# EdgeOne Pages Functions: AI OCR

This project demonstrates how to use a visual recognition large language model within Pages functions to identify text in images. The underlying model is based on Tencent's HunYuan large language model, which can be easily swapped out with other large language models using environment variables.

## Deploy

[![Deploy with EdgeOne Pages](https://cdnstatic.tencentcs.com/edgeone/pages/deploy.svg)](https://edgeone.ai/pages/new?from=github&template=functions-ocr)

More Templates: [EdgeOne Pages](https://edgeone.ai/pages/templates)

Live Demo: https://functions-ocr.edgeone.app

## Getting Started

First, run the development server:

```bash
npm run dev
# or
yarn dev
# or
pnpm dev
# or
bun dev
```

Open [http://localhost:3000](http://localhost:3000) with your browser to see the result.

You can start editing the page by modifying `app/page.tsx`. The page auto-updates as you edit the file.

This project uses [`next/font`](https://nextjs.org/docs/basic-features/font-optimization) to automatically optimize and load Inter, a custom Google Font.

## Learn More

To learn more about Next.js, take a look at the following resources:

- [Next.js Documentation](https://nextjs.org/docs) - learn about Next.js features and API.
- [Learn Next.js](https://nextjs.org/learn) - an interactive Next.js tutorial.

You can check out [the Next.js GitHub repository](https://github.com/vercel/next.js/) - your feedback and contributions are welcome!

## Credit

This project was inspired by [llama-ocr](https://github.com/Nutlope/llama-ocr). Go check them out!
